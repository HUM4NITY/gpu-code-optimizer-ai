# âš¡ GPU Code Optimizer AI

An AI-powered code analysis tool that uses **NVIDIA Nemotron models** via Ollama to identify GPU optimization opportunities in your code. Built for the NVIDIA GTC 2026 Golden Ticket Developer Contest.

![NVIDIA](https://img.shields.io/badge/NVIDIA-Nemotron-76B900?style=for-the-badge&logo=nvidia)
![Ollama](https://img.shields.io/badge/Ollama-Powered-000000?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi)

## ğŸ¯ What It Does

GPU Code Optimizer AI analyzes Python, CUDA, and C++ code to identify performance bottlenecks and suggest specific optimizations:

- **Memory Coalescing** - Detect uncoalesced memory accesses
- **Kernel Fusion** - Identify opportunities to combine kernels
- **Shared Memory** - Suggest shared memory optimizations
- **Tensor Core Utilization** - Recommend tensor core operations
- **GPU Occupancy** - Analyze thread block configurations
- **Memory Bandwidth** - Optimize data transfer patterns
- **Compute Intensity** - Improve arithmetic intensity
- **Parallelism** - Find parallelization opportunities

## ğŸš€ Quick Start

### Prerequisites

1. **Install Ollama**: [https://ollama.ai](https://ollama.ai)
2. **Install NVIDIA Nemotron model**:
   ```bash
   ollama pull nemotron
   ```
3. **Python 3.8+**

### Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/HUM4NITY/gpu-code-optimizer-ai.git
   cd gpu-code-optimizer-ai
   ```

2. Install Python dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Run the Application

#### Option 1: Simple Setup (Static Frontend)

```bash
python app.py
```

Then open your browser to: **http://localhost:8000**

#### Option 2: Modern UI (Next.js Frontend - Recommended!)

```bash
# Terminal 1 - Start Backend
python app.py

# Terminal 2 - Start Frontend
cd frontend
npm install
npm run dev
```

Then open your browser to: **http://localhost:3000**

The Next.js version includes:
- âœ¨ Polished UI with animations
- ğŸ“‹ Built-in code examples
- ğŸ¨ Modern design with shadcn/ui
- âš¡ Better performance

## ğŸ“– Usage

1. **Paste Your Code** - Enter Python, CUDA, or C++ GPU code
2. **Select Model** - Choose NVIDIA Nemotron or other available models
3. **Analyze** - Click "Analyze & Optimize"
4. **Get Results** - Receive detailed optimization suggestions with:
   - Severity levels (Critical, High, Medium, Low)
   - Specific issues and solutions
   - Code examples
   - Estimated speedup predictions

### Example Analysis

```python
import torch

def inefficient_batch_process(data):
    results = []
    for item in data:
        item_gpu = item.cuda()
        result = model(item_gpu)
        results.append(result.cpu())
    return results
```

**The AI will identify:**
- âŒ CPU-GPU transfer overhead
- âŒ No batch processing
- âŒ Synchronous execution
- âœ… **Suggested optimization**: Batch processing with single GPU transfer

## ğŸ—ï¸ Architecture

```
gpu-code-optimizer/
â”œâ”€â”€ app.py                 # FastAPI backend
â”œâ”€â”€ frontend/              # Next.js modern UI (recommended)
â”‚   â”œâ”€â”€ app/              # Next.js pages
â”‚   â”œâ”€â”€ components/       # React components
â”‚   â””â”€â”€ lib/              # API client & types
â”œâ”€â”€ static/               # Simple HTML/CSS/JS UI
â”‚   â”œâ”€â”€ index_v2.html    # Alternative web interface
â”‚   â”œâ”€â”€ style_v2.css     # Styling
â”‚   â””â”€â”€ script_v2.js     # Frontend logic
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # Documentation
```

**Tech Stack:**
- **Backend**: FastAPI for high-performance async API
- **AI Engine**: Ollama with NVIDIA Nemotron models
- **Frontend (Modern)**: Next.js 14, React, TypeScript, Tailwind CSS, shadcn/ui, Framer Motion
- **Frontend (Simple)**: Vanilla JavaScript (no build step!)
- **Analysis**: Custom prompt engineering for GPU optimization

## ğŸ® Features

### Real-Time Analysis
- Instant feedback on code quality
- Interactive web interface
- Multiple model support

### Comprehensive Detection
- Memory access patterns
- Kernel optimization opportunities
- Thread configuration issues
- Data transfer inefficiencies

### Actionable Insights
- Specific code examples
- Estimated performance gains
- Severity-based prioritization
- Category-based grouping

### Developer Friendly
- Simple setup (< 5 minutes)
- No GPU required to run the analyzer
- Works with existing code
- Export and share results

## ğŸ§ª Example Code Samples

The application includes built-in examples:

1. **Inefficient CUDA Kernel** - Matrix multiplication with poor memory access
2. **Python GPU Computing** - PyTorch code with optimization opportunities
3. **NumPy Vectorization** - CPU code that could benefit from GPU acceleration

Click "ğŸ“‹ Load Example" in the UI to try them!

## ğŸ”§ API Endpoints

### POST `/api/analyze`
Analyze code for GPU optimizations

**Request:**
```json
{
  "code": "your code here",
  "language": "python",
  "model": "nemotron"
}
```

**Response:**
```json
{
  "optimizations": [...],
  "summary": "Analysis summary",
  "overall_score": 85,
  "model_used": "nemotron"
}
```

### GET `/api/models`
List available Ollama models

### GET `/api/examples`
Get example code snippets

### GET `/api/health`
Health check endpoint

## ğŸ“ How It Works

1. **Code Submission** - User submits code through web interface
2. **Prompt Engineering** - System creates a detailed analysis prompt
3. **AI Analysis** - Nemotron model analyzes code for GPU patterns
4. **Result Parsing** - Structured JSON response with optimizations
5. **Visualization** - Results displayed with severity and categories

## ğŸ† NVIDIA GTC Contest Submission

This project is designed for the **NVIDIA GTC Golden Ticket Developer Contest**:

### Targets Multiple Challenges:
- âœ… **Ollama Challenge**: Built with Ollama and open models
- âœ… **Bryan Catanzaro**: Showcases NVIDIA Nemotron models
- âœ… **Sabrina Koumoin**: Demonstrates NVIDIA technology

### Why This Project Stands Out:
1. **Practical Value** - Solves real GPU optimization challenges
2. **NVIDIA Focus** - Directly aligned with GPU performance
3. **Nemotron Showcase** - Highlights model capabilities
4. **Open Source** - Community-driven development
5. **Production Ready** - Clean architecture, good UX

## ğŸš€ Future Enhancements

- [ ] Multi-file project analysis
- [ ] Integration with VS Code extension
- [ ] Performance benchmarking tools
- [ ] CI/CD pipeline integration
- [ ] Support for more languages (Rust, Julia)
- [ ] Automatic code refactoring
- [ ] Historical analysis tracking

## ğŸ“ License

MIT License - Feel free to use, modify, and distribute!

## ğŸ¤ Contributing

Contributions welcome! This is an open-source project for the NVIDIA developer community.

## ğŸ“§ Contact

Built by a developer passionate about GPU computing and AI.

**For NVIDIA GTC Contest:**
- Tag: #NVIDIAGTC
- Models: NVIDIA Nemotron via Ollama
- Category: Developer Tools, GPU Optimization, AI

## ğŸ™ Acknowledgments

- **NVIDIA** for Nemotron models and GPU technology
- **Ollama** for making model deployment simple
- **FastAPI** for excellent Python web framework
- **Open Source Community** for inspiration

---

**âš¡ Built with NVIDIA Nemotron | Powered by Ollama | For Developers, By Developers**
